{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hebrew_character                 Names  Frequencies\n",
      "0                אל            Alef_Lamed          800\n",
      "1               כול         Kaf_Waw_Lamed          788\n",
      "2               אשר        Alef_Shin_Resh          780\n",
      "3                על            Ayin_Lamed          710\n",
      "4                את              Alef_Taw          688\n",
      "5                כי               Kaf_Yod          423\n",
      "6               לוא        Lamed_Waw_Alef          361\n",
      "7                עד            Ayin_Dalet          340\n",
      "8                די             Dalet_Yod          339\n",
      "9                מן  Mem-medial_Nun-final          338\n",
      "10               לא            Lamed_Alef          286\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "#df.dtypes\n",
    "print(df[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we get from the network? Top x characters? Multiply by character probability\n",
    "TODO:\n",
    "Get character frequency\n",
    "Calculate character probability: freq/tot\n",
    "Calculate word probability: freq/tot\n",
    "Calculate levenshtein distance:\n",
    "1. create empty dict to save distances\n",
    "2. check if word is in given dictionary\n",
    "3. Yes? distance = 0, No? Find minimal distance\n",
    "4. Find minimal distance:\n",
    "5. delete / substitute / insert\n",
    "\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. check if word exists\n",
    "2. if not, calculate edit distances\n",
    "3. calculate final probability by min(edit_distance)*word_probability\n",
    "4. return max(final_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hebrew_character                 Names  Frequencies\n",
      "0                אל            Alef_Lamed          800\n",
      "1               כול         Kaf_Waw_Lamed          788\n",
      "2               אשר        Alef_Shin_Resh          780\n",
      "3                על            Ayin_Lamed          710\n",
      "4                את              Alef_Taw          688\n",
      "5                כי               Kaf_Yod          423\n",
      "6               לוא        Lamed_Waw_Alef          361\n",
      "7                עד            Ayin_Dalet          340\n",
      "8                די             Dalet_Yod          339\n",
      "9                מן  Mem-medial_Nun-final          338\n",
      "10               לא            Lamed_Alef          286\n",
      "dict_keys(['א', 'ל', 'כ', 'ו', 'ש', 'ר', 'ע', 'ת', 'י', 'ד', 'מ', 'ן', 'ם', 'ב', 'נ', 'ה', 'ח', 'פ', 'ק', 'ך', 'ט', 'ץ', 'צ', 'ז', 'ג', 'ף', 'ס'])\n",
      "א 1390\n",
      "ל 1828\n",
      "כ 842\n",
      "ו 3841\n",
      "ש 1236\n",
      "ר 1584\n",
      "ע 995\n",
      "ת 1491\n",
      "י 2737\n",
      "ד 835\n",
      "מ 1531\n",
      "ן 411\n",
      "ם 757\n",
      "ב 1796\n",
      "נ 876\n",
      "ה 2099\n",
      "ח 785\n",
      "פ 467\n",
      "ק 496\n",
      "ך 151\n",
      "ט 236\n",
      "ץ 44\n",
      "צ 303\n",
      "ז 248\n",
      "ג 259\n",
      "ף 54\n",
      "ס 222\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "print(df[:11])\n",
    "\n",
    "\n",
    "# Create a dictionary with all characters\n",
    "df = df['Hebrew_character'].values.tolist()\n",
    "#df = [word.split('_') for word in df]\n",
    "#print(df)\n",
    "character_dic = {}\n",
    "for word in df:\n",
    "    for letter in word:\n",
    "        if letter not in character_dic:\n",
    "            character_dic[letter] = 0\n",
    "        character_dic[letter] += 1\n",
    "\n",
    "        \n",
    "print(character_dic.keys())        \n",
    "for key, value in character_dic.items():\n",
    "    print(str(key) + ' ' + str(value))    \n",
    "#print(len(character_dic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alef': 1390, 'Lamed': 1828, 'Kaf': 842, 'Waw': 3841, 'Shin': 1236, 'Resh': 1584, 'Ayin': 995, 'Taw': 1491, 'Yod': 2737, 'Dalet': 835, 'Mem-medial': 1531, 'Nun-final': 411, 'Mem': 757, 'Bet': 1796, 'Nun-medial': 876, 'He': 2099, 'Het': 785, 'Pe': 467, 'Qof': 496, 'Kaf-final': 151, 'Tet': 236, 'Tasdi-final': 44, 'Tsadi': 303, 'Zayin': 248, 'Gimel': 259, 'Pe-final': 54, 'Samekh': 222}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "df2 = df['Names'].values.tolist()\n",
    "#df3 = [word.replace('_',' ') for word in df2]\n",
    "#print (df3)\n",
    "\n",
    "df4 = [word.split() for word in df3]\n",
    "#print(df4)\n",
    "#df5 = [word.append() for word in df4]\n",
    "df5 = []\n",
    "for words in df4:\n",
    "    for word in words:\n",
    "        df5.append(word)\n",
    "dic1 = {}\n",
    "for word in df5:\n",
    "    if word not in dic1:\n",
    "        dic1[word] = 0\n",
    "    dic1[word] += 1\n",
    "print(dic1)\n",
    "print (len(dic1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alef 1390\n",
      "Ayin 995\n",
      "Bet 1796\n",
      "Dalet 835\n",
      "Gimel 259\n",
      "He 2099\n",
      "Het 785\n",
      "Kaf 842\n",
      "Kaf-final 151\n",
      "Lamed 1828\n",
      "Mem 757\n",
      "Mem-medial 1531\n",
      "Nun-final 411\n",
      "Nun-medial 876\n",
      "Pe 467\n",
      "Pe-final 54\n",
      "Qof 496\n",
      "Resh 1584\n",
      "Samekh 222\n",
      "Shin 1236\n",
      "Tasdi-final 44\n",
      "Taw 1491\n",
      "Tet 236\n",
      "Tsadi 303\n",
      "Waw 3841\n",
      "Yod 2737\n",
      "Zayin 248\n"
     ]
    }
   ],
   "source": [
    "for dic in sorted(dic1): print(dic + \" \" + str(dic1[dic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('הימים', 236.33936087341053)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    d = {}\n",
    "    lens1 = len(s1)\n",
    "    lens2 = len(s2)\n",
    "    \n",
    "    for i in range(-1,lens1+1):\n",
    "        d[(i,-1)] = i+1\n",
    "        \n",
    "    for j in range(-1,lens2+1):\n",
    "        d[(-1,j)] = j+1\n",
    " \n",
    "    for i in range(lens1):\n",
    "        for j in range(lens2):\n",
    "            if s1[i] == s2[j]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[(i,j)] = min(\n",
    "                           d[(i-1,j)] + 1,\n",
    "                           d[(i,j-1)] + 1, \n",
    "                           d[(i-1,j-1)] + cost,\n",
    "                          )\n",
    "    return d[lens1-1,lens2-1]\n",
    "\n",
    "ngrams = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "#df = ngrams['Hebrew_character'].values.tolist(df = ngrams['Hebrew_character'].values.tolist(')\n",
    "#print(df[:11])\n",
    "\n",
    "\n",
    "#TODO\n",
    "# dont rely only on edit distance, take prob with mindist\n",
    "# Think of proper formula\n",
    "\n",
    "import math\n",
    "def bestGuess(checkword):\n",
    "    distlist = []\n",
    "    mindist = float('inf')\n",
    "    freqsum = ngrams['Frequencies'].sum()\n",
    "    \n",
    "    for row in ngrams.itertuples():\n",
    "        word = row.Hebrew_character\n",
    "        prob = round(row.Frequencies / freqsum * 100,6)\n",
    "        dist = levenshtein(checkword, word)\n",
    "        # test formula:\n",
    "        dist = math.exp(dist)/prob\n",
    "        #print (dist)\n",
    "        if dist == mindist:\n",
    "            #distlist.append([word,dist,prob])\n",
    "            distlist.append([word,dist])\n",
    "            \n",
    "        if dist < mindist:\n",
    "            #distlist = [[word,dist,prob]]\n",
    "            distlist = [[word,dist]]\n",
    "            mindist = dist\n",
    "            \n",
    "    return distlist\n",
    "\n",
    "\n",
    "bestGuess('הימהימים')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "0\n",
      "\n",
      "אל\n",
      "\n",
      "Alef_Lamed\n",
      "\n",
      "800\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
