{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import PIL.Image\n",
    "import math\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "from keras.models import load_model\n",
    "from util.WordSegmentation import wordSegmentation, prepareImg\n",
    "from sklearn.preprocessing import normalize\n",
    "from natsort import natsorted\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"Alef\",\n",
    "    \"Ayin\",\n",
    "    \"Bet\",\n",
    "    \"Dalet\",\n",
    "    \"Gimel\",\n",
    "    \"He\",\n",
    "    \"Het\",\n",
    "    \"Kaf\",\n",
    "    \"Kaf-final\",\n",
    "    \"Lamed\",\n",
    "    \"Mem\",\n",
    "    \"Mem-medial\",\n",
    "    \"Nun-final\",\n",
    "    \"Nun-medial\",\n",
    "    \"Pe\",\n",
    "    \"Pe-final\",\n",
    "    \"Qof\",\n",
    "    \"Resh\",\n",
    "    \"Samekh\",\n",
    "    \"Shin\",\n",
    "    \"Taw\",\n",
    "    \"Tet\",\n",
    "    \"Tsadi-final\",\n",
    "    \"Tsadi-medial\",\n",
    "    \"Waw\",\n",
    "    \"Yod\",\n",
    "    \"Zayin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# model = load_model('temporary.best.hdf5')\n",
    "# new_model = tf.keras.experimental.load_from_saved_model(saved_model_path)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# import_images = []\n",
    "# import_images.append(prepareImg(cv2.imread('input_files_word_old/slice4.png'), 50))\n",
    "# showarray(import_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = 'output_files/image-data/'\n",
    "\n",
    "def load_slices(filepath):\n",
    "    slices = []\n",
    "    slices_filepath = filepath + '/'\n",
    "    slices_path = natsorted(glob.glob(slices_filepath + 'slice*_binarize.png'))\n",
    "    for slice_path in slices_path:\n",
    "        slices.append(prepareImg(cv2.imread(slice_path), 50))  \n",
    "    #print(len(slices))\n",
    "    return slices\n",
    "\n",
    "image_filepaths = glob.glob(input_files + '*')\n",
    "print(image_filepaths)\n",
    "print(image_filepaths[len(image_filepaths) - 5])\n",
    "images = []\n",
    "for image_filepath in image_filepaths:\n",
    "    images.append(load_slices(image_filepath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of black pixels in an image and return a float with the density\n",
    "def pixel_density(image):\n",
    "    area = float(image.shape[0]*image.shape[1])\n",
    "    blackPixels = float(np.sum(image == 0))\n",
    "    density = blackPixels/area\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# res = []\n",
    "# words = []\n",
    "# for i, img in enumerate(import_images):\n",
    "#     res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=30) # fix parameters\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#There still needs to come a loop through all the slices, here you can pick a slice to debug\n",
    "# img = images[12][5]\n",
    "# showarray(img)\n",
    "#Parameters are optimized. \n",
    "segments = []\n",
    "for (i, img) in enumerate(images):\n",
    "    for (j, slic) in enumerate(img):\n",
    "        res = wordSegmentation(slic, kernelSize=13, sigma=3, theta=((slic.shape[1] / slic.shape[0]) / 4), minArea=15 * 15)\n",
    "        segments.append({\n",
    "            \"res\": res,\n",
    "            \"img\": i,\n",
    "            \"slic\": j\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "segments_1 = []\n",
    "for (i, seg) in enumerate(segments):\n",
    "    words = []\n",
    "    places = []\n",
    "    for (j, w) in enumerate(seg[\"res\"]):\n",
    "        (wordBox, wordImg) = w\n",
    "        (x, y, w, h) = wordBox\n",
    "        words.append(wordImg)\n",
    "        segments_1.append({\n",
    "            \"img\": seg[\"img\"],\n",
    "            \"slic\": seg[\"slic\"],\n",
    "            \"word\": wordImg,\n",
    "            \"word_place\": y\n",
    "        })\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "segments_2 = []\n",
    "\n",
    "for (i, seg) in enumerate(segments_1):\n",
    "    res = wordSegmentation(seg[\"word\"], kernelSize=5, sigma=3, theta=1, minArea=70) # fix parameters\n",
    "\n",
    "    for (j, w) in enumerate(res):\n",
    "        (charBox, charImg) = w\n",
    "        (x, y, w, h) = charBox\n",
    "\n",
    "        if( pixel_density(charImg) < 0.55):\n",
    "            segments_2.append({\n",
    "                \"img\": seg[\"img\"],\n",
    "                \"slic\": seg[\"slic\"],\n",
    "                \"word_place\": seg[\"word_place\"],\n",
    "                \"word\": seg[\"word\"],\n",
    "                \"char_place\": y,\n",
    "                \"char\": charImg\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for the bounding boxes over the words again to possible find characters. It will return the box of the entire word\n",
    "#when it does not find seperate characters in the word. \n",
    "#The character needs a minimum width of 15, height of 10 and maximum density of 55%\n",
    "\n",
    "\n",
    "segments_3 = []\n",
    "average_char_width = 17\n",
    "offset_rounding_err = 0.3\n",
    "\n",
    "for (i, seg) in enumerate(segments_2):\n",
    "    char = seg[\"char\"]\n",
    "    factor = round(((char.shape[1]) / average_char_width) - offset_rounding_err)\n",
    "    if factor > 1:\n",
    "        for i in range(factor):\n",
    "            full_width = char.shape[1]\n",
    "            width = math.floor(full_width / factor)\n",
    "            slic = width * i;\n",
    "            new_char = char[:, slic:slic+width]\n",
    "            \n",
    "            segments_3.append({\n",
    "                \"img\": seg[\"img\"],\n",
    "                \"slic\": seg[\"slic\"],\n",
    "                \"word_place\": seg[\"word_place\"],\n",
    "                \"word\": seg[\"word\"],\n",
    "                \"char_place\": seg[\"char_place\"] + slic,\n",
    "                \"char\": new_char\n",
    "            })\n",
    "    else:\n",
    "        segments_3.append(seg);\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in segments_3:\n",
    " showarray(seg[\"char\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "##### word = words[2]\n",
    "h, w = word.shape\n",
    "num = 4\n",
    "chars = []\n",
    "for i in range(num):\n",
    "    part = math.floor(w / num)\n",
    "    char = word[:,part * i:(part * i) + part]\n",
    "    shape = cv2.resize(char,(32,48))\n",
    "    ret,thresh1 = cv2.threshold(shape,127,255,cv2.THRESH_BINARY)\n",
    "    chars.append(thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import ipywidgets as widgets\n",
    "# import random\n",
    "# import uuid\n",
    "\n",
    "# if not os.path.isdir(\"generated\"):\n",
    "#     os.mkdir(\"generated\")\n",
    "# hebrews = os.listdir(\"habbakuk\")\n",
    "# chosen = \"\"\n",
    "\n",
    "# def on_button_clicked(v):\n",
    "#     if not os.path.isdir(\"generated/\" + v.description):\n",
    "#         os.mkdir(\"generated/\" + v.description)\n",
    "        \n",
    "#     cv2.imwrite(\"generated/\" + v.description + \"/\" + str(uuid.uuid1()) + \".png\", seg[\"char\"]);\n",
    "#     clear_output()\n",
    "#     generate(i)\n",
    "    \n",
    "# def undo_button_clicked(d):\n",
    "#     clear_output()\n",
    "#     generate(i)\n",
    "    \n",
    "# def generate(index):\n",
    "#     global chosen\n",
    "#     seg = random.choice(segments_3)\n",
    "#     chosen = seg\n",
    "#     showarray(seg[\"word\"])\n",
    "#     showarray(seg[\"char\"])\n",
    "#     undo = widgets.Button(\n",
    "#         description=\"I don't know\"    \n",
    "#     )\n",
    "#     undo.on_click(undo_button_clicked)\n",
    "#     display(undo)\n",
    "#     wids = []\n",
    "#     for (i, hebrew) in enumerate(hebrews):\n",
    "#         file = open(\"habbakuk/\" + hebrew + \"/img_modefilter_5.png\", \"rb\")\n",
    "#         image = file.read()\n",
    "#         img = widgets.Image(\n",
    "#             value=image,\n",
    "#             format='png',\n",
    "#             width=40,\n",
    "#             height=440,\n",
    "#         )\n",
    "#         btn = widgets.Button(\n",
    "#             description=hebrew,\n",
    "#         )\n",
    "#         btn.on_click(on_button_clicked)\n",
    "#         wids.append(widgets.HBox([img, btn]))\n",
    "        \n",
    "#         if i % 5 == 4:\n",
    "#             display(widgets.HBox(wids))\n",
    "#             wids = []\n",
    "#     display(widgets.HBox(wids))\n",
    "            \n",
    "# generate(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fonts = []\n",
    "for item in class_names:\n",
    "    fonts.append(cv2.imread('habbakuk/' + item + '/standard.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for seg in segments_3:\n",
    "    char = seg[\"char\"]\n",
    "#     char_pred = cv2.cvtColor(char, cv2.COLOR_BGR2GRAY)\n",
    "    char_pred = np.asarray(char[:], dtype='float32')\n",
    "    print(char_pred.shape)\n",
    "    char_pred = normalize(char_pred)\n",
    "    char_pred = char_pred.reshape(-1, 48, 32,1)\n",
    "\n",
    "    prediction = model.predict([char_pred])\n",
    "    for i in range(len(prediction)):\n",
    "        print('Predicted: ', prediction[i] * 100)\n",
    "    highest_index = np.argmax(prediction)\n",
    "    print('Index of class with highest probability: ',highest_index)\n",
    "    print('Value of highest probability: ', prediction[0][highest_index])\n",
    "    print('Name of predicted class: ', class_names[highest_index])\n",
    "    print('habbabuk/' + class_names[highest_index] + '/standard.png')\n",
    "    character_example = cv2.imread('habbakuk/' + str(class_names[highest_index]) + '/standard.png')\n",
    "    showarray(character_example)\n",
    "    showarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# for box in bounding_boxes:\n",
    "#     xStart = box[2]\n",
    "#     xEnd = box[0]\n",
    "#     y = box[1]\n",
    "#     winH = box[3] - y\n",
    "#     winWidth = 5\n",
    "#     while(xStart-winWidth >= xEnd) :\n",
    "#         hit = False\n",
    "#         winW = winWidth\n",
    "#         a = 0\n",
    "#         # While the image is not classified and the box has not reached the edge,\n",
    "#         # increase window size\n",
    "#         while(not hit and xStart-winW >= xEnd) :\n",
    "#             newX = xStart - winW\n",
    "#             # Draw the window\n",
    "#             clone = img.copy()\n",
    "#             cv2.rectangle(clone, (xStart, y), (newX, y + winH), (255, 0, 0), 2)\n",
    "#             cv2.rectangle(clone, (xStart,y),(xEnd,y + winH), (0,255,0), 2)\n",
    "#             cv2.imshow(\"Window\", clone)\n",
    "#             cv2.waitKey(0)\n",
    "#             # Check if the CNN returns a high probability for a letter\n",
    "#             # for prob in probabilities :\n",
    "#             #     if prob >= 0.75 :\n",
    "#             #         hit = True\n",
    "#             #         xStart = newX\n",
    "#             # # Increase size of window if nothing has been found\n",
    "#             winW += 5\n",
    "#             # this is done to ensure that the loop ends for now, because not\n",
    "#             # connected to cnn yet.\n",
    "#             hit = True\n",
    "#             xStart = newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# def get_resized_img(img, video_size):\n",
    "#     width, height = video_size  # these are the MAX dimensions\n",
    "#     video_ratio = width / height\n",
    "#     img_ratio = img.size[0] / img.size[1]\n",
    "#     if video_ratio >= 1:  # the video is wide\n",
    "#         if img_ratio <= video_ratio:  # image is not wide enough\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#         else:  # image is wider than video\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#     else:  # the video is tall\n",
    "#         if img_ratio >= video_ratio:  # image is not tall enough\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#         else:  # image is taller than video\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#     return np.asarray(img.resize(size_new, resample=Image.LANCZOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# char = cv2.cvtColor(char, char, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 0,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.1.6"
   }
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
