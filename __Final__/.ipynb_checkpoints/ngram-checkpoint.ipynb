{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank hebrew  probability\n",
      "1     1     של     0.500000\n",
      "2     2     את     0.250000\n",
      "4     3     על     0.166667\n",
      "5     4     לא     0.125000\n",
      "6     5    הוא     0.100000\n",
      "7     6     עם     0.083333\n",
      "9     7     כי     0.071429\n",
      "10    8    היה     0.062500\n",
      "11    9     זה     0.055556\n",
      "12   10     גם     0.050000\n",
      "13   11      ב     0.045455\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "#df.dtypes\n",
    "#print(df[:11])\n",
    "\n",
    "corpus = pd.read_excel (r'Hebrew.xlsx')\n",
    "\n",
    "#Read in the excel with frequency list of Hebrew words\n",
    "corpus['hebrew'] = corpus.iloc[:, 3] #Get the words\n",
    "corpus['rank'] = corpus.iloc[:, 0] #Get their rank\n",
    "corpus.dropna(axis=0, inplace=True) #Remove all rows with empty values\n",
    "corpus = corpus[['rank', 'hebrew']] \n",
    "corpus = corpus.iloc[1:] #Remove first row\n",
    "corpus['hebrew'] = corpus['hebrew'].str.strip() #Remove whitespace\n",
    "corpus = corpus[corpus['rank'] != 'Rank'] #remove header rows\n",
    "\n",
    "corpus['probability'] = 1/(corpus['rank'].astype(dtype='float')*2) #Add a probability based on the rank of the word.\n",
    "\n",
    "#print(corpus[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we get from the network? Top x characters? Multiply by character probability\n",
    "TODO:\n",
    "Get character frequency\n",
    "Calculate character probability: freq/tot\n",
    "Calculate word probability: freq/tot\n",
    "Calculate levenshtein distance:\n",
    "1. create empty dict to save distances\n",
    "2. check if word is in given dictionary\n",
    "3. Yes? distance = 0, No? Find minimal distance\n",
    "4. Find minimal distance:\n",
    "5. delete / substitute / insert\n",
    "\n",
    "\n",
    "\n",
    "Steps:\n",
    "1. check if word exists\n",
    "2. if not, calculate edit distances\n",
    "3. calculate final probability by min(edit_distance)*word_probability\n",
    "4. return max(final_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hebrew_character                 Names  Frequencies\n",
      "0                אל            Alef_Lamed          800\n",
      "1               כול         Kaf_Waw_Lamed          788\n",
      "2               אשר        Alef_Shin_Resh          780\n",
      "3                על            Ayin_Lamed          710\n",
      "4                את              Alef_Taw          688\n",
      "5                כי               Kaf_Yod          423\n",
      "6               לוא        Lamed_Waw_Alef          361\n",
      "7                עד            Ayin_Dalet          340\n",
      "8                די             Dalet_Yod          339\n",
      "9                מן  Mem-medial_Nun-final          338\n",
      "10               לא            Lamed_Alef          286\n",
      "[['Alef', 'Lamed'], ['Kaf', 'Waw', 'Lamed'], ['Alef', 'Shin', 'Resh'], ['Ayin', 'Lamed'], ['Alef', 'Taw'], ['Kaf', 'Yod'], ['Lamed', 'Waw', 'Alef'], ['Ayin', 'Dalet'], ['Dalet', 'Yod'], ['Mem-medial', 'Nun-final'], ['Lamed', 'Alef']]\n",
      "dict_keys(['Alef', 'Lamed', 'Kaf', 'Waw', 'Shin', 'Resh', 'Ayin', 'Taw', 'Yod', 'Dalet', 'Mem-medial', 'Nun-final', 'Mem', 'Bet', 'Nun-medial', 'He', 'Het', 'Pe', 'Qof', 'Kaf-final', 'Tet', 'Tasdi-final', 'Tsadi', 'Zayin', 'Gimel', 'Pe-final', 'Samekh'])\n",
      "Alef 1390\n",
      "Lamed 1828\n",
      "Kaf 842\n",
      "Waw 3841\n",
      "Shin 1236\n",
      "Resh 1584\n",
      "Ayin 995\n",
      "Taw 1491\n",
      "Yod 2737\n",
      "Dalet 835\n",
      "Mem-medial 1531\n",
      "Nun-final 411\n",
      "Mem 757\n",
      "Bet 1796\n",
      "Nun-medial 876\n",
      "He 2099\n",
      "Het 785\n",
      "Pe 467\n",
      "Qof 496\n",
      "Kaf-final 151\n",
      "Tet 236\n",
      "Tasdi-final 44\n",
      "Tsadi 303\n",
      "Zayin 248\n",
      "Gimel 259\n",
      "Pe-final 54\n",
      "Samekh 222\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "print(df[:11])\n",
    "\n",
    "\n",
    "# Create a dictionary with all characters\n",
    "#df = df['Hebrew_character'].values.tolist()\n",
    "df = df['Names'].values.tolist()\n",
    "df = [word.split('_') for word in df]\n",
    "print(df[:11])\n",
    "character_dic = {}\n",
    "for word in df:\n",
    "    for letter in word:\n",
    "        if letter not in character_dic:\n",
    "            character_dic[letter] = 0\n",
    "        character_dic[letter] += 1\n",
    "\n",
    "        \n",
    "print(character_dic.keys())        \n",
    "for key, value in character_dic.items():\n",
    "    print(str(key) + ' ' + str(value))    \n",
    "#print(len(character_dic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alef': 1390, 'Lamed': 1828, 'Kaf': 842, 'Waw': 3841, 'Shin': 1236, 'Resh': 1584, 'Ayin': 995, 'Taw': 1491, 'Yod': 2737, 'Dalet': 835, 'Mem-medial': 1531, 'Nun-final': 411, 'Mem': 757, 'Bet': 1796, 'Nun-medial': 876, 'He': 2099, 'Het': 785, 'Pe': 467, 'Qof': 496, 'Kaf-final': 151, 'Tet': 236, 'Tasdi-final': 44, 'Tsadi': 303, 'Zayin': 248, 'Gimel': 259, 'Pe-final': 54, 'Samekh': 222}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "#print(df[:11])\n",
    "#df2 = df['Names'].values.tolist()\n",
    "#df3 = [word.replace('_',' ') for word in df2]\n",
    "#print (df3)\n",
    "\n",
    "df4 = df\n",
    "\n",
    "#df4 = [word.split() for word in df3]\n",
    "#print(df4)\n",
    "#df5 = [word.append() for word in df4]\n",
    "df5 = []\n",
    "for words in df4:\n",
    "    for word in words:\n",
    "        df5.append(word)\n",
    "dic1 = {}\n",
    "for word in df5:\n",
    "    if word not in dic1:\n",
    "        dic1[word] = 0\n",
    "    dic1[word] += 1\n",
    "print(dic1)\n",
    "print (len(dic1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alef 1390\n",
      "Ayin 995\n",
      "Bet 1796\n",
      "Dalet 835\n",
      "Gimel 259\n",
      "He 2099\n",
      "Het 785\n",
      "Kaf 842\n",
      "Kaf-final 151\n",
      "Lamed 1828\n",
      "Mem 757\n",
      "Mem-medial 1531\n",
      "Nun-final 411\n",
      "Nun-medial 876\n",
      "Pe 467\n",
      "Pe-final 54\n",
      "Qof 496\n",
      "Resh 1584\n",
      "Samekh 222\n",
      "Shin 1236\n",
      "Tasdi-final 44\n",
      "Taw 1491\n",
      "Tet 236\n",
      "Tsadi 303\n",
      "Waw 3841\n",
      "Yod 2737\n",
      "Zayin 248\n"
     ]
    }
   ],
   "source": [
    "for dic in sorted(dic1): print(dic + \" \" + str(dic1[dic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Levensthein difference\n",
    "def levenshtein(s1, s2):\n",
    "    d = {}\n",
    "    lens1 = len(s1)\n",
    "    lens2 = len(s2)\n",
    "    \n",
    "    for i in range(-1,lens1+1):\n",
    "        d[(i,-1)] = i+1\n",
    "        \n",
    "    for j in range(-1,lens2+1):\n",
    "        d[(-1,j)] = j+1\n",
    " \n",
    "    for i in range(lens1):\n",
    "        for j in range(lens2):\n",
    "            if s1[i] == s2[j]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[(i,j)] = min(\n",
    "                           d[(i-1,j)] + 1,\n",
    "                           d[(i,j-1)] + 1, \n",
    "                           d[(i-1,j-1)] + cost,\n",
    "                          )\n",
    "    return d[lens1-1,lens2-1]\n",
    "\n",
    "ngrams = pd.read_excel (r'ngrams_frequencies_withNames.xlsx')\n",
    "#df = ngrams['Hebrew_character'].values.tolist(df = ngrams['Hebrew_character'].values.tolist(')\n",
    "#print(df[:11])\n",
    "\n",
    "\n",
    "#Returns the best guess for a word based on N-Grams\n",
    "import math\n",
    "def bestGuess(checkword):\n",
    "    distlist = []\n",
    "    mindist = float('inf')\n",
    "    freqsum = ngrams['Frequencies'].sum()\n",
    "    \n",
    "    for row in ngrams.itertuples():\n",
    "        word = row.Hebrew_character #Get the hebrew characters from corpus line\n",
    "        prob = round(row.Frequencies / freqsum * 100,6) #Probability of word compared to all words in corpus\n",
    "        dist = levenshtein(checkword, word) #Compare the to check word with corpus word. \n",
    "        # test formula:\n",
    "        dist = math.exp(dist)/prob\n",
    "        #Check if the current distance is the smallest and update if so.  \n",
    "        if dist == mindist:\n",
    "            #distlist.append([word,dist,prob])\n",
    "            distlist.append([word,dist])\n",
    "            \n",
    "        if dist < mindist:\n",
    "            #distlist = [[word,dist,prob]]\n",
    "            distlist = [[word,dist]]\n",
    "            mindist = dist\n",
    "            \n",
    "    return distlist\n",
    "\n",
    "#returns best guess for a word based on corpus\n",
    "def bestGuess2(checkword):\n",
    "    distlist = []\n",
    "    mindist = float('inf')\n",
    "    \n",
    "    for row in corpus.itertuples():\n",
    "        word = row.hebrew #Get the hebrew characters from corpus line\n",
    "        prob = row.probability #Probability of word compared to all words in corpus\n",
    "        dist = levenshtein(checkword, word) #Compare the to check word with corpus word. \n",
    "\n",
    "        # test formula:\n",
    "        dist = math.exp(dist)/prob\n",
    "        #Check if the current distance is the smallest and update if so. \n",
    "        if dist == mindist:\n",
    "            #distlist.append([word,dist,prob])\n",
    "            distlist.append([word,dist])\n",
    "            \n",
    "        if dist < mindist:\n",
    "            #distlist = [[word,dist,prob]]\n",
    "            distlist = [[word,dist]]\n",
    "            mindist = dist\n",
    "            \n",
    "    return distlist\n",
    "\n",
    "#print(bestGuess('תעמידנ֯ו'))\n",
    "#print(bestGuess2('תעמידנ֯ו'))\n",
    "#bestGuess('ולוא')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "תעמידנ֯ו לשארית֯ להם לתת לנו הקימות לאברהם לישראל ולהוריש\n",
      "של של לא הוא של את של את של \n",
      "תעמידנ֯ולשארית֯להםלתתלנוהקימותלאברהםלישראלולהוריש\n"
     ]
    }
   ],
   "source": [
    "def reverse_string(s):\n",
    "    \"\"\"Return a reversed copy of `s`\"\"\"\n",
    "    return s[::-1]\n",
    "\n",
    "def remove_characters_at_end(string, number):\n",
    "    string = reverse_string(string)\n",
    "    string = string[:len(string)-number]\n",
    "    return reverse_string(string)\n",
    "\n",
    "#Line from the ground truth used to test. The real input would eb the predictions from the network. \n",
    "line = 'תעמידנ֯ו לשארית֯ להם לתת לנו הקימות לאברהם לישראל ולהוריש'\n",
    "word_level = line.split() \n",
    "score_word_level = 0.0 #Distance score for the sentence with spaces as is. \n",
    "new_line_word_level = \"\"\n",
    "\n",
    "#On a word level, create the mostly likely sentence using the ngram data. \n",
    "for word in word_level:\n",
    "    lst = bestGuess2(word)\n",
    "    score_word_level = score_word_level + lst[0][1]\n",
    "    new_line_word_level =  lst[0][0] + \" \" + new_line_word_level\n",
    "    \n",
    "print(line)\n",
    "print(new_line_word_level)\n",
    "\n",
    "#remove spaces from the line\n",
    "line_no_spacing = line.replace(\" \", \"\")\n",
    "max_word_length = 8\n",
    "total_score_letters = 0.0\n",
    "new_line = \"\" \n",
    "print(line_no_spacing)\n",
    "#Create the sentnce with spacing as deemed most likely through the frequency information. \n",
    "while len(line_no_spacing) > 1:\n",
    "    score = 0.0\n",
    "    lowest_score = 1000\n",
    "    lowest_idx = 0\n",
    "    for i in range(1,max_word_length):\n",
    "        #Try to find the combination of 1-max_word_length characters that has the best score\n",
    "        #Then save it and remove it from the line_no_spacing.\n",
    "        tmp = reverse_string(line_no_spacing)\n",
    "        word = reverse_string(tmp[len(tmp)-i:])\n",
    "        score = bestGuess2(word)[0][1]/(i*i) #Favor longer words by deviding by the prediced word length.\n",
    "\n",
    "        if score < lowest_score:\n",
    "            lowest_score = score\n",
    "            lowest_idx = i\n",
    "            lowest_word = word\n",
    "    \n",
    "    #Remove the word selected from the line and update score and new line. \n",
    "    line_no_spacing = remove_characters_at_end(line_no_spacing, lowest_idx)\n",
    "    total_score_letters += lowest_score\n",
    "    new_line = lowest_word + \" \" + new_line\n",
    "\n",
    "print(total_score_letters) #distance score of sentence created by the language model\n",
    "print(score_word_level) #distance score of the original scentence \n",
    "print(new_line) #sentence created by the language model\n",
    "print(line) #original sentence that was input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hwr",
   "language": "python",
   "name": "hwr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
