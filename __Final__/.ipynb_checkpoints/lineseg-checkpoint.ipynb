{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: (3, 7, 3)\n",
      "OpenCV version: 4.1.0\n"
     ]
    }
   ],
   "source": [
    "from sys import version_info\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import find_peaks_cwt, find_peaks\n",
    "print('Python version: ' + str(version_info[:3]))\n",
    "print('OpenCV version: ' + cv2.__version__)\n",
    "def undesired_objects (image):\n",
    "    image = image.astype('uint8')\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2, nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "            \n",
    "    img2 = np.zeros(output.shape)\n",
    "    img2[output == max_label] = 255\n",
    "    cv2.imwrite(\"output_files/biggest_component.png\", img2)\n",
    "    return img2\n",
    "\n",
    "def inverted(imagem):\n",
    "    imagem = (255-imagem)\n",
    "    return imagem\n",
    "    \n",
    "def imshow_components(labels):\n",
    "    # Map component labels to hue val\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # cvt to BGR for display\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "\n",
    "    cv2.imwrite('output_files/connected_components.png', labeled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Read image, and perform binarization using Otsu algorithm\\nimg = cv2.imread('input_files/test7.jpg')  #Afbeelding waar je alles op uitvoert\\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\\n#Perform OTSU binarization\\nret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\\n#Show  and save image\\ncv2.imwrite('output_files/otsu.png',thresh)\\n#Find connected components of image\\noutput_components = cv2.connectedComponentsWithStats(cv2.bitwise_not(thresh))\\n# The first cell is the number of labels\\nnum_labels = output_components[0]\\n# The second cell is the label matrix\\nlabels = output_components[1]\\n# The third cell is the stat matrix\\nstats = output_components[2]\\n# The fourth cell is the centroid matrix\\ncentroids = output_components[3]\\n#Show the components of the image\\nimshow_components(labels)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Read image, and perform binarization using Otsu algorithm\n",
    "img = cv2.imread('input_files/test7.jpg')  #Afbeelding waar je alles op uitvoert\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#Perform OTSU binarization\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "#Show  and save image\n",
    "cv2.imwrite('output_files/otsu.png',thresh)\n",
    "#Find connected components of image\n",
    "output_components = cv2.connectedComponentsWithStats(cv2.bitwise_not(thresh))\n",
    "# The first cell is the number of labels\n",
    "num_labels = output_components[0]\n",
    "# The second cell is the label matrix\n",
    "labels = output_components[1]\n",
    "# The third cell is the stat matrix\n",
    "stats = output_components[2]\n",
    "# The fourth cell is the centroid matrix\n",
    "centroids = output_components[3]\n",
    "#Show the components of the image\n",
    "imshow_components(labels)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Get the biggest components, the dead sea scroll.\\nlargest_component = undesired_objects(cv2.bitwise_not(thresh))\\n#Convert to right type\\nlargest_component = largest_component.astype('uint8')\\n#Save file for debugging purposes. \\ncv2.imwrite('output_files/is_dit_het_nou.png', largest_component)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Get the biggest components, the dead sea scroll.\n",
    "largest_component = undesired_objects(cv2.bitwise_not(thresh))\n",
    "#Convert to right type\n",
    "largest_component = largest_component.astype('uint8')\n",
    "#Save file for debugging purposes. \n",
    "cv2.imwrite('output_files/is_dit_het_nou.png', largest_component)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlargest_component_copy = largest_component\\ncontours, hierarchy = cv2.findContours(largest_component, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\\nbounding_boxes = [cv2.boundingRect(contour) for contour in contours]\\n\\nprint(bounding_boxes)\\nx = bounding_boxes[0][0]\\ny = bounding_boxes[0][1]\\nwidth = bounding_boxes[0][2]\\nheight = bounding_boxes[0][3]\\n#Crop the image to get only the scroll\\ncrop_img = largest_component_copy[y:y+height, x:x+width]\\ncv2.imwrite('output_files/crop.png', crop_img)\\n#Draw rectangle around the largest component to see what is being cropped. \\ncv2.rectangle(largest_component_copy,(x,y),(x+width,y+height),(255,0,0),2)\\ncv2.imwrite('output_files/vierkant.png', largest_component_copy)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "largest_component_copy = largest_component\n",
    "contours, hierarchy = cv2.findContours(largest_component, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "\n",
    "print(bounding_boxes)\n",
    "x = bounding_boxes[0][0]\n",
    "y = bounding_boxes[0][1]\n",
    "width = bounding_boxes[0][2]\n",
    "height = bounding_boxes[0][3]\n",
    "#Crop the image to get only the scroll\n",
    "crop_img = largest_component_copy[y:y+height, x:x+width]\n",
    "cv2.imwrite('output_files/crop.png', crop_img)\n",
    "#Draw rectangle around the largest component to see what is being cropped. \n",
    "cv2.rectangle(largest_component_copy,(x,y),(x+width,y+height),(255,0,0),2)\n",
    "cv2.imwrite('output_files/vierkant.png', largest_component_copy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncrop_img2 = img[y:y+height, x:x+width]\\n\\n\\n# noise removal\\nkernel = np.ones((3,3),np.uint8)\\nopening = cv2.morphologyEx(crop_img,cv2.MORPH_OPEN,kernel, iterations = 2)\\n#Save image for debugging\\ncv2.imwrite('output_files/opening.png',opening)\\n# sure background area\\nsure_bg = cv2.dilate(opening,kernel,iterations=3)\\n# Finding sure foreground area\\ndist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\\nret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\\n#Save image for debugging\\ncv2.imwrite('output_files/dist_transform.png',dist_transform)\\n# Finding unknown region\\nsure_fg = np.uint8(sure_fg)\\nunknown = cv2.subtract(sure_bg,sure_fg)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "crop_img2 = img[y:y+height, x:x+width]\n",
    "\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(crop_img,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "#Save image for debugging\n",
    "cv2.imwrite('output_files/opening.png',opening)\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "#Save image for debugging\n",
    "cv2.imwrite('output_files/dist_transform.png',dist_transform)\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite('output_files/fg.png',sure_fg)\n",
    "#cv2.imwrite('output_files/bg.png',sure_bg)\n",
    "#cv2.imwrite('output_files/unkown.png',unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Marker labelling\\nret, markers = cv2.connectedComponents(sure_fg)\\n# Add one to all labels so that sure background is not 0, but 1\\nmarkers = markers+1\\n# Now, mark the region of unknown with zero\\nmarkers[unknown==255] = 0\\ncv2.imwrite('output_files/markers.png',markers)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "cv2.imwrite('output_files/markers.png',markers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Perform watershed and save the result. \\nmarkers = cv2.watershed(crop_img2,markers)\\ncrop_img2[markers == -1] = [0,255,0]\\ncv2.imwrite('output_files/watershed_output.png',crop_img2)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Perform watershed and save the result. \n",
    "markers = cv2.watershed(crop_img2,markers)\n",
    "crop_img2[markers == -1] = [0,255,0]\n",
    "cv2.imwrite('output_files/watershed_output.png',crop_img2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getHist(inputimg, mask):    \n",
    "    #inputimg = cv2.bitwise_not(inputimg)\n",
    "    #kernel2 = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "    #inputimg = cv2.dilate(inputimg,kernel2,iterations = 2)\n",
    "    if np.amax(inputimg) == 255:\n",
    "        binary_img = inputimg / 255\n",
    "    else:\n",
    "        binary_img = inputimg  \n",
    "    height, width = binary_img.shape\n",
    "    hist = []\n",
    "    for x in range(height):\n",
    "        # find indexes of start and end of paper\n",
    "        pixels = np.where(mask[x] == 255)\n",
    "        if len(pixels[0])>0:\n",
    "            rightp = pixels[0][-1]\n",
    "            leftp = pixels[0][0]\n",
    "            #calculate paper width\n",
    "            paperw = rightp-leftp\n",
    "            if paperw > 10:\n",
    "                #sum number of white pixels\n",
    "                rowsum = binary_img[x].sum()\n",
    "                normsum = rowsum/paperw\n",
    "                if normsum > 1:\n",
    "                    hist.append(hist[-1])\n",
    "                    print(normsum)\n",
    "                else:\n",
    "                    hist.append(normsum)\n",
    "            else:\n",
    "                hist.append(0)\n",
    "        else:\n",
    "            hist.append(0)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def rotate_hist(input_img, mask, folder):\n",
    "    i = 0\n",
    "    hists = []\n",
    "    for angle in np.arange(-15,18,3):\n",
    "        rotated = imutils.rotate_bound(input_img, angle)\n",
    "        rotatedMask = imutils.rotate_bound(mask, angle)\n",
    "        hists.append(getHist(rotated, rotatedMask))\n",
    "        i += 1\n",
    "\n",
    "    avg = 0\n",
    "    best_peaks = []\n",
    "    for j in range(i):\n",
    "        hist = hists[j]\n",
    "        #plt.bar(range(1,1+len(hist)),hist)\n",
    "        plt.plot(range(1,1+len(hist)),hist)\n",
    "        peaks, _ = find_peaks(hist, width=5, distance = len(hist)/40, height = max(hist)/5)\n",
    "       # plt.plot(hist.index[peaks], hist.water_level[hist], 'ro', label = 'positive peaks')\n",
    "       # print(hist[list(peaks)])\n",
    "        peakplot = [hist[i] for i in peaks]\n",
    "        #plt.plot(peaks,peakplot,'ro')\n",
    "        #print (peakplot)\n",
    "        summed = np.sum(peakplot)\n",
    "        divided = summed/len(peakplot)\n",
    "        if divided > avg :\n",
    "            avg = divided\n",
    "            best_peaks = peaks\n",
    "            index_angle = j\n",
    "       \n",
    "    best_angle = -15+index_angle*3\n",
    "    #print(best_peaks)\n",
    "    cv2.imwrite(folder+'rotatedHist.png',imutils.rotate_bound(input_img,best_angle))\n",
    "    return best_angle, best_peaks;\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(opening)\n",
    "#plt.hlines(best_peaks,0,len(opening[0])-1,colors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median\n",
    "\n",
    "def hole_removal (image, percentile, newfolder):\n",
    "    image = image.astype('uint8')\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    sizes = stats[:, -1]\n",
    "    #Show components of the image\n",
    "    imshow_components(output)\n",
    "    #Calculate the threshold to remove holes\n",
    "    sizes_copy = np.delete(sizes, np.argmax(sizes))\n",
    "    avg = np.average(sizes_copy)\n",
    "    #The x percentile is used as a threshold\n",
    "    val = np.percentile(sizes_copy, percentile)\n",
    "    var_threshold = val\n",
    "    print(avg)\n",
    "    print(val)\n",
    "    #We also create an absolute threshold to not accidentally remove small characters\n",
    "    abs_threshold = 1500\n",
    "    \n",
    "    ####################PIXEL DENSITY##########################\n",
    "    #Calculate the pixel density for each component\n",
    "    pixel_density = np.zeros(nb_components+1)\n",
    "    #for i in range(2, nb_components):\n",
    "    #    #convert connected component to an image and get white pixel density\n",
    "    #    img1 = np.zeros(output.shape)\n",
    "    #    img1[output == i] = 255\n",
    "    #    cv2.imwrite(\"output_files/biggest_componenttemp.png\", img1)\n",
    "    #    pixel_density[i] = pixel_density_connected_component(img1, image)\n",
    "    #    #raw_input(\"Press Enter to continue...\")\n",
    "    \n",
    "    #Calculate the desnity threshold with a percentile. \n",
    "    #density_threshold = np.percentile(pixel_density, 25)\n",
    "    ##############################################\n",
    "    \n",
    "    #Create empty image, only add components smaller than the threshold\n",
    "    img2 = np.zeros(output.shape)\n",
    "    mask_holes = np.zeros(output.shape)\n",
    "    for i in range(2, nb_components):\n",
    "        if sizes[i] <= var_threshold:\n",
    "            img2[output == i] = 255\n",
    "        elif sizes[i] <= abs_threshold:\n",
    "            img2[output == i] = 255\n",
    "        #elif sizes[i] > var_threshold:\n",
    "         #   if pixel_density[i] <= density_threshold:\n",
    "         #       img2[output == i] = 255\n",
    "        else:\n",
    "            mask_holes[output == i] = 255\n",
    "    mask_holes = mask_holes.astype('uint8')       \n",
    "    #cv2.imwrite(\"output_files/hole_mask.png\", mask_holes)\n",
    "    cv2.imwrite(newfolder+'hole_mask.png',mask_holes)\n",
    "    return img2, mask_holes\n",
    "  \n",
    "def binarizeSlice(slice, folder, y):\n",
    "    img = cv2.imread(slice)\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    kernel1 = np.ones((3,3),np.uint8)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,70,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    erode = cv2.erode(cv2.bitwise_not(thresh),kernel, iterations = 3)\n",
    "    opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, kernel1)\n",
    "    closing = cv2.morphologyEx(erode, cv2.MORPH_CLOSE, kernel1)\n",
    "    erode = cv2.erode(closing,kernel, iterations = 3)\n",
    "    cv2.imwrite(folder+'slice'+str(y)+'_binarize.png',cv2.bitwise_not(erode))\n",
    "    \n",
    "\n",
    "def binarizeSliceOtsu(slice, folder, y):\n",
    "    img = cv2.imread(slice)\n",
    "    kernel = np.ones((1,1),np.uint8)\n",
    "    kernel1 = np.ones((3,3),np.uint8)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)   \n",
    "    \n",
    "    erode = cv2.erode(thresh,kernel, iterations = 3)\n",
    "    opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, kernel1)\n",
    "    closing = cv2.morphologyEx(erode, cv2.MORPH_CLOSE, kernel1)\n",
    "    erode = cv2.erode(closing,kernel, iterations = 3)\n",
    "    cv2.imwrite(folder+'slice_binarize_Otsu'+str(y)+'.png',cv2.bitwise_not(erode))\n",
    "\n",
    "# slices papyrus in little papyri\n",
    "def sliceImg(inputimg, slices, folder, original, mask, hole_mask):\n",
    "    if np.amax(inputimg) == 1:\n",
    "        paper = inputimg * 255\n",
    "    else:\n",
    "        paper = inputimg\n",
    "    height, width = paper.shape\n",
    "    lastslice = 0\n",
    "    for x in range(height):\n",
    "        if sum(paper[x]) > 0:\n",
    "            lastslice = x\n",
    "            break\n",
    "    #paper = cv2.bitwise_not(paper)\n",
    "    mask = mask.astype('uint8')\n",
    "    original = cv2.bitwise_and(original, original, mask=mask)\n",
    "    kleuren = np.unique(original)\n",
    "    #whiteor[:] = median(kleuren[int(len(kleuren)/2):])\n",
    "    whiteor = np.random.randint(kleuren[int(len(kleuren)/2)],kleuren[-1], size=(height, width,3),dtype=np.uint8)\n",
    "    mask = mask - hole_mask\n",
    "    whiteor = cv2.bitwise_and(whiteor,whiteor, mask=cv2.bitwise_not(mask))\n",
    "    original = cv2.add(whiteor,original)\n",
    "    \n",
    "    y = 1\n",
    "    for y in range(len(slices)):\n",
    "        #check if slice is big enough\n",
    "        #if slices[y]-lastslice > height/(len(slices)*4):\n",
    "        #cv2.imwrite(folder+'slice'+str(y)+'.png',paper[lastslice:slices[y]])\n",
    "        cv2.imwrite(folder+'slice'+str(y)+'.png',original[lastslice:slices[y]])        \n",
    "        lastslice = slices[y]\n",
    "        binarizeSlice(folder+'slice'+str(y)+'.png', folder, y)\n",
    "        binarizeSliceOtsu(folder+'slice'+str(y)+'.png', folder, y)\n",
    "    onderkant = height\n",
    "    for x in reversed(range(height)):\n",
    "        if sum(paper[x]) > 0:\n",
    "            onderkant = x\n",
    "            break\n",
    "    cv2.imwrite(folder+'slice'+str(y+1)+'.png',original[lastslice:onderkant])  \n",
    "    binarizeSlice(folder+'slice'+str(y+1)+'.png', folder, y+1)\n",
    "    \n",
    "def imshow_components2(labels):\n",
    "    # Map component labels to hue val\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # cvt to BGR for display\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue==0] = 0\n",
    "\n",
    "    return labeled_img\n",
    "\n",
    "\n",
    "\n",
    "def pixel_density_connected_component (connectedComponent, image):\n",
    "    #Make sure image is of correct type\n",
    "    connectedComponent = connectedComponent.astype('uint8')\n",
    "    \n",
    "    #Create bounding box around largest component with contours\n",
    "    _, contours, hierarchy = cv2.findContours(connectedComponent, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "\n",
    "    #Get the appropriate coordinates\n",
    "    x = bounding_boxes[0][0]\n",
    "    y = bounding_boxes[0][1]\n",
    "    width = bounding_boxes[0][2]\n",
    "    height = bounding_boxes[0][3]\n",
    "    \n",
    "    #Crop image to bounding box arround component\n",
    "    crop_img = image[y:y+height, x:x+width]\n",
    "    cv2.imwrite('output_files/cropped_component.png', crop_img)\n",
    "    #Calculate density of the this newly create image of component\n",
    "    area = float(crop_img.shape[0]*crop_img.shape[1])\n",
    "    whitePixels = float(np.sum(crop_img == 255))\n",
    "    density = whitePixels/area\n",
    "    #print(\"whitePixels: {}\".format(whitePixels))\n",
    "    #print(\"area: {}\".format(area))\n",
    "    #print(\"density: {}\".format(density))\n",
    "\n",
    "    return density\n",
    "\n",
    "#Not in use currently\n",
    "def img_fill(im_th):  # n = binary image threshold\n",
    "    # Copy the thresholded image.\n",
    "    im_floodfill = im_th.copy()\n",
    "\n",
    "    # Mask used to flood filling.\n",
    "    # Notice the size needs to be 2 pixels than the image.\n",
    "    h, w = im_th.shape[:2]\n",
    "    mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0, 0), 255);\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the foreground.\n",
    "    fill_image = im_th | im_floodfill_inv\n",
    "\n",
    "    return fill_image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(NOT USED ATM) Appends all images from one folder in a list\n",
    "import glob\n",
    "#import cv2\n",
    "def readFolder(path):\n",
    "    extension = 'jpg'\n",
    "    image_list = []\n",
    "    if len(glob.glob(path+'*.'+extension)) > 0:\n",
    "        for filename in glob.glob(path+'*.'+extension):\n",
    "            image_list.append(cv2.imread(filename))\n",
    "    else:\n",
    "        print('ERROR: There were no {} files found in folder {}'.format(extension, path))\n",
    "    return image_list\n",
    "\n",
    "imlist = readFolder('input_files/image-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with processing of 20 files\n",
      "Processing P123-Fg002-R-C01-R01-fused\n",
      "391.3893967093236\n",
      "3928.866000000102\n",
      "Processing P583-Fg002-R-C01-R01-fused\n",
      "735.1276595744681\n",
      "5077.269000000017\n",
      "1.2857142857142858\n",
      "1.5\n",
      "1.5454545454545454\n",
      "1.2857142857142858\n",
      "1.5\n",
      "1.5454545454545454\n",
      "1.0655971479500892\n",
      "1.221453287197232\n",
      "1.2985620915032678\n",
      "1.1633053221288514\n",
      "1.151734539969834\n",
      "1.2727272727272727\n",
      "1.1338562091503268\n",
      "1.196358543417367\n",
      "1.3519607843137254\n",
      "1.2887700534759359\n",
      "1.3245852187028657\n",
      "1.260633484162896\n",
      "1.5098039215686276\n",
      "1.0713725490196078\n",
      "1.3266968325791857\n",
      "1.4601307189542485\n",
      "1.0183823529411764\n",
      "1.4081447963800904\n",
      "Processing P583-Fg006-R-C01-R01-fused\n",
      "957.4468085106383\n",
      "6530.513000000015\n",
      "Processing P106-Fg002-R-C01-R01-fused\n",
      "323.8491620111732\n",
      "23600.153000000977\n",
      "Processing P21-Fg006-R-C01-R01-fused\n",
      "106.26984126984127\n",
      "3545.880000000041\n",
      "Processing P22-Fg008-R-C01-R01-fused\n",
      "120.20501138952164\n",
      "927.9340000000004\n",
      "Processing P632-Fg001-R-C01-R01-fused\n",
      "154.2887473460722\n",
      "1647.280000000017\n",
      "Processing P632-Fg002-R-C01-R01-fused\n",
      "386.2808988764045\n",
      "2142.584\n",
      "Processing P846-Fg001-R-C01-R01-fused\n",
      "255.69892473118279\n",
      "1257.4850000000004\n",
      "Processing P168-Fg016-R-C01-R01-fused\n",
      "439.6363636363636\n",
      "2275.0500000000015\n",
      "Processing P344-Fg001-R-C01-R01-fused\n",
      "301.88878416588125\n",
      "23642.0400000007\n",
      "Processing P423-1-Fg002-R-C01-R01-fused\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "# Processes all images in a folder and saves them to separate folders\n",
    "def processImages(path):\n",
    "    extension = 'jpg'\n",
    "    if len(glob.glob(path+'*.'+extension)) > 0:\n",
    "        print('Started with processing of {} files'.format(len(glob.glob(path+'*.'+extension))))\n",
    "        for file in glob.glob(path+'*.'+extension):\n",
    "            newfolder = 'output_files/image-data/'+file.rsplit('.',1)[0].rsplit('/',1)[1]+'/'\n",
    "            print('Processing ' + newfolder.rsplit('/',1)[0].rsplit('/',1)[1])\n",
    "            if not os.path.exists(newfolder):\n",
    "                os.makedirs(newfolder)\n",
    "            \n",
    "            #Read image, and perform binarization using Otsu algorithm\n",
    "            img = cv2.imread(file)\n",
    "            \n",
    "            cv2.imwrite(newfolder+'original.png',img)\n",
    "            \n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #Create an extra thresholded image of original\n",
    "            ret, thresholded_img = cv2.threshold(gray, 17, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            #Perform OTSU binarization\n",
    "            ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "            #Show  and save image\n",
    "            cv2.imwrite(newfolder+'otsu.png',thresh)\n",
    "            \n",
    "            #Find connected components of image\n",
    "            output_components = cv2.connectedComponentsWithStats(cv2.bitwise_not(thresh))\n",
    "            # The first cell is the number of labels\n",
    "            num_labels = output_components[0]\n",
    "            # The second cell is the label matrix\n",
    "            labels = output_components[1]\n",
    "            # The third cell is the stat matrix\n",
    "            stats = output_components[2]\n",
    "            # The fourth cell is the centroid matrix\n",
    "            centroids = output_components[3]\n",
    "            #print the components of the image\n",
    "            labeled_img = imshow_components2(labels)\n",
    "            cv2.imwrite(newfolder+'connected_components.png', labeled_img)\n",
    "            \n",
    "            #Get the biggest components, the dead sea scroll.\n",
    "            largest_component = undesired_objects(cv2.bitwise_not(thresh))\n",
    "            #Convert to right type\n",
    "            largest_component = largest_component.astype('uint8')\n",
    "            #Save file for debugging purposes.\n",
    "            cv2.imwrite(newfolder+'is_dit_het_nou.png', largest_component)\n",
    "            \n",
    "            #Lex 09-06\n",
    "            crop_img = largest_component\n",
    "            ###################################################################\n",
    "            kernel2 = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "            kernel3 = np.array([[1,1],[1,1]])\n",
    "            dilated_img = cv2.dilate(crop_img,kernel2,iterations = 2)\n",
    "            cv2.imwrite(newfolder+'dilated.png', dilated_img)\n",
    "\n",
    "            #Get the countours of the scroll\n",
    "            contours, hierarchy = cv2.findContours(dilated_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            img2 = np.zeros(crop_img.shape)\n",
    "            img_contour = cv2.drawContours(img2, contours, -1, 255, -1)\n",
    "\n",
    "            #dilate and erode to fill up the edges of the scroll.\n",
    "            img_contour = cv2.dilate(img_contour,kernel2,iterations = 6)\n",
    "            img_contour = cv2.erode(img_contour,kernel2,iterations = 10)\n",
    "            cv2.imwrite(newfolder+'contours.png', img_contour)\n",
    "            \n",
    "            #Create a mask for just the big holes. \n",
    "            only_big_holes = np.zeros(img_contour.shape)\n",
    "\n",
    "            # grab the image dimensions\n",
    "            h = img_contour.shape[0]\n",
    "            w = img_contour.shape[1]\n",
    "            \n",
    "            # loop over the image, pixel by pixel\n",
    "            for y in range(0, h):\n",
    "                for x in range(0, w):\n",
    "                    # threshold the pixel\n",
    "                    only_big_holes[y, x] = thresholded_img[y,x] if img_contour[y, x] > 0 else 0\n",
    "                    #only_big_holes[y, x] = thresh[y,x] if img_contour[y, x] > 0 else 0\n",
    "\n",
    "\n",
    "            only_big_holes = cv2.morphologyEx(only_big_holes, cv2.MORPH_CLOSE, kernel2, iterations = 4)\n",
    "            only_big_holes = cv2.morphologyEx(only_big_holes, cv2.MORPH_OPEN, kernel2, iterations = 2)\n",
    "            cv2.imwrite(newfolder+'only_big_holes.png', only_big_holes)\n",
    "            \n",
    "            #create a mask of the big holes where the big holes are in white on a black BG\n",
    "            \n",
    "            #Create a mask for just the big holes. \n",
    "            big_hole_mask = np.zeros(img_contour.shape)\n",
    "            \n",
    "            big_hole_mask = cv2.bitwise_not(only_big_holes.astype('uint8')) - cv2.bitwise_not(img_contour.astype('uint8'))\n",
    "            big_hole_mask = cv2.dilate(big_hole_mask,kernel2,iterations = 2)\n",
    "            cv2.imwrite(newfolder+'big_hole_mask.png', big_hole_mask)\n",
    "\n",
    "            #Convert the shape of the scroll to binarized image and invert.  \n",
    "            ret, mask = cv2.threshold(img_contour, 127, 255, cv2.THRESH_BINARY)\n",
    "            mask = mask.astype('uint8')\n",
    "            mask = cv2.bitwise_not(mask)\n",
    "            cv2.imwrite(newfolder+'mask.png', mask)\n",
    "\n",
    "            #Add the mask to the original image to delete background. \n",
    "            added = crop_img + mask\n",
    "            #added = cv2.morphologyEx(added, cv2.MORPH_CLOSE, kernel3, iterations = 3)\n",
    "            #added = cv2.morphologyEx(added, cv2.MORPH_CLOSE, kernel2, iterations = 1)\n",
    "            cv2.imwrite(newfolder+'added.png', added)\n",
    "\n",
    "            #Get rid of noise, especially at the edges\n",
    "            added = cv2.morphologyEx(added, cv2.MORPH_CLOSE, kernel2, iterations = 1)\n",
    "\n",
    "            #To debug: show largest connected component of the result. \n",
    "            mask = undesired_objects(cv2.bitwise_not(added))\n",
    "            cv2.imwrite(newfolder+'added_inv.png', cv2.bitwise_not(added))\n",
    "            \n",
    "            #Run hole removal function and save resulting image and hole mask\n",
    "            output_hole_removal, general_hole_mask = hole_removal(cv2.bitwise_not(added), 99.9,newfolder)\n",
    "            output_hole_removal = output_hole_removal.astype('uint8')\n",
    "            general_hole_mask = general_hole_mask.astype('uint8')\n",
    "            \n",
    "            cv2.imwrite(newfolder+'holes_removed.png', cv2.bitwise_not(output_hole_removal))\n",
    "            \n",
    "            #Subtract the big holes from the image as well seieng as these are detected with a different method. \n",
    "            output_hole_removal = output_hole_removal - big_hole_mask\n",
    "            cv2.imwrite(newfolder+'holes_removed_subtracted.png', cv2.bitwise_not(output_hole_removal))\n",
    "            \n",
    "            #Create 1 mask with all the hole information\n",
    "            general_hole_mask = general_hole_mask + big_hole_mask\n",
    "            cv2.imwrite(newfolder+'general_hole_mask.png', general_hole_mask)\n",
    "                \n",
    "            # noise removal\n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            opening = cv2.morphologyEx(largest_component,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "            #Save image for debugging\n",
    "            cv2.imwrite(newfolder+'opening.png',opening)\n",
    "            \n",
    "            #hist = getHist(opening)\n",
    "            #hist = getHist(output_hole_removal, img_contour)\n",
    "            angle,peaks = rotate_hist(output_hole_removal, img_contour, newfolder)\n",
    "            \n",
    "            imutils.rotate_bound(output_hole_removal,angle)\n",
    "            imutils.rotate_bound(img,angle)\n",
    "            imutils.rotate_bound(img_contour,angle)\n",
    "            imutils.rotate_bound(general_hole_mask,angle)\n",
    "            \n",
    "            #peaks, _ = find_peaks(hist, height = sum(hist)/len(hist), distance = len(hist)/20)\n",
    "            #peaks, _ = find_peaks(hist, distance = len(hist)/40, height = max(hist)/2)\n",
    "            #widths=np.arange(1)\n",
    "            #peaks = find_peaks_cwt(hist, widths)\n",
    "            #peaks, _ = find_peaks(hist, width=5, distance = len(hist)/40, height = max(hist)/5)\n",
    "            peaks2 = []\n",
    "            for x in range(len(peaks)-1):\n",
    "                peaks2.append(int((peaks[x]+peaks[x+1])/2))\n",
    "            sliceImg(output_hole_removal,peaks2,newfolder,img,img_contour, general_hole_mask)\n",
    "            #sliceImg(output_hole_removal,peaks2,newfolder,gray,img_contour)\n",
    "            peakplot = [hist[i] for i in peaks]\n",
    "            plt.plot(range(1,1+len(hist)),hist)\n",
    "            plt.plot(peaks,peakplot,'ro')\n",
    "            plt.savefig(newfolder+'histogram.png',dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            #plt.imshow(output_hole_removal)\n",
    "            plt.imshow(cv2.bitwise_and(img, img, mask=img_contour.astype('uint8')))\n",
    "            plt.hlines(peaks2,0,len(output_hole_removal[0])-1,colors='w')\n",
    "            plt.savefig(newfolder+'holes_removed_lines.png',dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "        print('FINISHED! Files saved in folders in the {} folder'.format(path.rsplit('/',1)[0].rsplit('/',1)[1]))\n",
    "    else:\n",
    "        print('ERROR: There were no {} files found in folder {}'.format(extension, path))\n",
    "\n",
    "\n",
    "processImages('input_files/image-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
