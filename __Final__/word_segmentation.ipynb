{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import PIL.Image\n",
    "import math\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "from keras.models import load_model\n",
    "from util.WordSegmentation import wordSegmentation, prepareImg\n",
    "from sklearn.preprocessing import normalize\n",
    "from natsort import natsorted\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"Alef\",\n",
    "    \"Ayin\",\n",
    "    \"Bet\",\n",
    "    \"Dalet\",\n",
    "    \"Gimel\",\n",
    "    \"He\",\n",
    "    \"Het\",\n",
    "    \"Kaf\",\n",
    "    \"Kaf-final\",\n",
    "    \"Lamed\",\n",
    "    \"Mem\",\n",
    "    \"Mem-medial\",\n",
    "    \"Nun-final\",\n",
    "    \"Nun-medial\",\n",
    "    \"Pe\",\n",
    "    \"Pe-final\",\n",
    "    \"Qof\",\n",
    "    \"Resh\",\n",
    "    \"Samekh\",\n",
    "    \"Shin\",\n",
    "    \"Taw\",\n",
    "    \"Tet\",\n",
    "    \"Tsadi-final\",\n",
    "    \"Tsadi-medial\",\n",
    "    \"Waw\",\n",
    "    \"Yod\",\n",
    "    \"Zayin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "model = load_model('temporary.best.hdf5')\n",
    "# new_model = tf.keras.experimental.load_from_saved_model(saved_model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import_images = []\n",
    "import_images.append(prepareImg(cv2.imread('input_files_word_old/slice4.png'), 50))\n",
    "showarray(import_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = 'output_files/image-data/'\n",
    "\n",
    "def load_slices(filepath):\n",
    "    slices = []\n",
    "    slices_filepath = filepath + '/'\n",
    "    slices_path = natsorted(glob.glob(slices_filepath + 'slice*_binarize.png'))\n",
    "    for slice_path in slices_path:\n",
    "        slices.append(prepareImg(cv2.imread(slice_path), 50))  \n",
    "    #print(len(slices))\n",
    "    return slices\n",
    "\n",
    "image_filepaths = glob.glob(input_files + '*')\n",
    "print(image_filepaths[len(image_filepaths) - 5])\n",
    "images = []\n",
    "for image_filepath in image_filepaths:\n",
    "    images.append(load_slices(image_filepath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of black pixels in an image and return a float with the density\n",
    "def pixel_density(image):\n",
    "    area = float(image.shape[0]*image.shape[1])\n",
    "    blackPixels = float(np.sum(image == 0))\n",
    "    density = blackPixels/area\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "res = []\n",
    "words = []\n",
    "for i, img in enumerate(import_images):\n",
    "    res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=30) # fix parameters\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There still needs to come a loop through all the slices, here you can pick a slice to debug\n",
    "img = images[1][5]\n",
    "showarray(img)\n",
    "#Parameters are optimized. \n",
    "res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for (j, w) in enumerate(res):\n",
    "    (wordBox, wordImg) = w\n",
    "    (x, y, w, h) = wordBox\n",
    "    if (w > 15):\n",
    "        if( h > 15):\n",
    "            words.append(wordImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "words.reverse()\n",
    "for word in words:\n",
    "    showarray(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for the bounding boxes over the words again to possible find characters. It will return the box of the entire word\n",
    "#when it does not find seperate characters in the word. \n",
    "#The character needs a minimum width of 15, height of 10 and maximum density of 55%\n",
    "characters = []\n",
    "temp = []\n",
    "for word in words:\n",
    "    res = wordSegmentation(word, kernelSize=3, sigma=1, theta=1, minArea=15) # fix parameters\n",
    "\n",
    "    for (j, w) in enumerate(res):\n",
    "        (charBox, charImg) = w\n",
    "        (x, y, w, h) = charBox\n",
    "        if (w > 15):\n",
    "            if( h > 15):\n",
    "                if( pixel_density(charImg) < 0.55):\n",
    "                    characters.append(charImg)\n",
    "\n",
    "for char in characters:\n",
    "    showarray(char)\n",
    "    #print(pixel_density(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "##### word = words[2]\n",
    "h, w = word.shape\n",
    "num = 4\n",
    "chars = []\n",
    "for i in range(num):\n",
    "    part = math.floor(w / num)\n",
    "    char = word[:,part * i:(part * i) + part]\n",
    "    shape = cv2.resize(char,(32,48))\n",
    "    ret,thresh1 = cv2.threshold(shape,127,255,cv2.THRESH_BINARY)\n",
    "    chars.append(thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "chars = characters\n",
    "for char in chars:\n",
    "    showarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fonts = []\n",
    "for item in class_names:\n",
    "    fonts.append(cv2.imread('habbakuk/' + item + '/standard.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for char in chars:\n",
    "#     char_pred = cv2.cvtColor(char, cv2.COLOR_BGR2GRAY)\n",
    "    char_pred = np.asarray(char[:], dtype='float32')\n",
    "    print(char_pred.shape)\n",
    "    char_pred = normalize(char_pred)\n",
    "    char_pred = char_pred.reshape(-1, 48, 32,1)\n",
    "\n",
    "    prediction = model.predict([char_pred])\n",
    "    for i in range(len(prediction)):\n",
    "        print('Predicted: ', prediction[i] * 100)\n",
    "    highest_index = np.argmax(prediction)\n",
    "    print('Index of class with highest probability: ',highest_index)\n",
    "    print('Value of highest probability: ', prediction[0][highest_index])\n",
    "    print('Name of predicted class: ', class_names[highest_index])\n",
    "    print('habbabuk/' + class_names[highest_index] + '/standard.png')\n",
    "    character_example = cv2.imread('habbakuk/' + str(class_names[highest_index]) + '/standard.png')\n",
    "    showarray(character_example)\n",
    "    showarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# for box in bounding_boxes:\n",
    "#     xStart = box[2]\n",
    "#     xEnd = box[0]\n",
    "#     y = box[1]\n",
    "#     winH = box[3] - y\n",
    "#     winWidth = 5\n",
    "#     while(xStart-winWidth >= xEnd) :\n",
    "#         hit = False\n",
    "#         winW = winWidth\n",
    "#         a = 0\n",
    "#         # While the image is not classified and the box has not reached the edge,\n",
    "#         # increase window size\n",
    "#         while(not hit and xStart-winW >= xEnd) :\n",
    "#             newX = xStart - winW\n",
    "#             # Draw the window\n",
    "#             clone = img.copy()\n",
    "#             cv2.rectangle(clone, (xStart, y), (newX, y + winH), (255, 0, 0), 2)\n",
    "#             cv2.rectangle(clone, (xStart,y),(xEnd,y + winH), (0,255,0), 2)\n",
    "#             cv2.imshow(\"Window\", clone)\n",
    "#             cv2.waitKey(0)\n",
    "#             # Check if the CNN returns a high probability for a letter\n",
    "#             # for prob in probabilities :\n",
    "#             #     if prob >= 0.75 :\n",
    "#             #         hit = True\n",
    "#             #         xStart = newX\n",
    "#             # # Increase size of window if nothing has been found\n",
    "#             winW += 5\n",
    "#             # this is done to ensure that the loop ends for now, because not\n",
    "#             # connected to cnn yet.\n",
    "#             hit = True\n",
    "#             xStart = newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# def get_resized_img(img, video_size):\n",
    "#     width, height = video_size  # these are the MAX dimensions\n",
    "#     video_ratio = width / height\n",
    "#     img_ratio = img.size[0] / img.size[1]\n",
    "#     if video_ratio >= 1:  # the video is wide\n",
    "#         if img_ratio <= video_ratio:  # image is not wide enough\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#         else:  # image is wider than video\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#     else:  # the video is tall\n",
    "#         if img_ratio >= video_ratio:  # image is not tall enough\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#         else:  # image is taller than video\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#     return np.asarray(img.resize(size_new, resample=Image.LANCZOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# char = cv2.cvtColor(char, char, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "hwr",
   "language": "python",
   "name": "hwr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
