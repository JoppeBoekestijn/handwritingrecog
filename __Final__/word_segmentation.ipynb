{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import PIL.Image\n",
    "import math\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "from keras.models import load_model\n",
    "from util.WordSegmentation import wordSegmentation, prepareImg\n",
    "from sklearn.preprocessing import normalize\n",
    "from natsort import natsorted\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "    # device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"Alef\",\n",
    "    \"Ayin\",\n",
    "    \"Bet\",\n",
    "    \"Dalet\",\n",
    "    \"Gimel\",\n",
    "    \"He\",\n",
    "    \"Het\",\n",
    "    \"Kaf\",\n",
    "    \"Kaf-final\",\n",
    "    \"Lamed\",\n",
    "    \"Mem\",\n",
    "    \"Mem-medial\",\n",
    "    \"Nun-final\",\n",
    "    \"Nun-medial\",\n",
    "    \"Pe\",\n",
    "    \"Pe-final\",\n",
    "    \"Qof\",\n",
    "    \"Resh\",\n",
    "    \"Samekh\",\n",
    "    \"Shin\",\n",
    "    \"Taw\",\n",
    "    \"Tet\",\n",
    "    \"Tsadi-final\",\n",
    "    \"Tsadi-medial\",\n",
    "    \"Waw\",\n",
    "    \"Yod\",\n",
    "    \"Zayin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# model = load_model('temporary.best.hdf5')\n",
    "# # new_model = tf.keras.experimental.load_from_saved_model(saved_model_path)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import_images = []\n",
    "import_images.append(prepareImg(cv2.imread('input_files_word_old/slice4.png'), 50))\n",
    "showarray(import_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-03f960cf35af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimage_filepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filepaths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_filepath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_filepaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "input_files = 'output_files/image-data/'\n",
    "\n",
    "def load_slices(filepath):\n",
    "    slices = []\n",
    "    slices_filepath = filepath + '/'\n",
    "    slices_path = natsorted(glob.glob(slices_filepath + 'slice*_binarize.png'))\n",
    "    for slice_path in slices_path:\n",
    "        slices.append(prepareImg(cv2.imread(slice_path), 50))  \n",
    "    #print(len(slices))\n",
    "    return slices\n",
    "\n",
    "image_filepaths = glob.glob(input_files + '*')\n",
    "print(image_filepaths[len(image_filepaths) - 5])\n",
    "images = []\n",
    "for image_filepath in image_filepaths:\n",
    "    images.append(load_slices(image_filepath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of black pixels in an image and return a float with the density\n",
    "def pixel_density(image):\n",
    "    area = float(image.shape[0]*image.shape[1])\n",
    "    blackPixels = float(np.sum(image == 0))\n",
    "    density = blackPixels/area\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nres = []\\nwords = []\\nfor i, img in enumerate(import_images):\\n    res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=30) # fix parameters\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "res = []\n",
    "words = []\n",
    "for i, img in enumerate(import_images):\n",
    "    res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=30) # fix parameters\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7bfc946732e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#There still needs to come a loop through all the slices, here you can pick a slice to debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshowarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Parameters are optimized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordSegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernelSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminArea\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "#There still needs to come a loop through all the slices, here you can pick a slice to debug\n",
    "img = images[1][6]\n",
    "showarray(img)\n",
    "#Parameters are optimized. \n",
    "res = wordSegmentation(img, kernelSize=5, sigma=5, theta=7, minArea=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-74867400ae9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mwordBox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwordImg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordBox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for (j, w) in enumerate(res):\n",
    "    (wordBox, wordImg) = w\n",
    "    (x, y, w, h) = wordBox\n",
    "    if (w > 15):\n",
    "        if( h > 15):\n",
    "            words.append(wordImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "words.reverse()\n",
    "for word in words:\n",
    "    showarray(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for the bounding boxes over the words again to possible find characters. It will return the box of the entire word\n",
    "#when it does not find seperate characters in the word. \n",
    "#The character needs a minimum width of 15, height of 10 and maximum density of 55%\n",
    "characters = []\n",
    "temp = []\n",
    "for word in words:\n",
    "    res = wordSegmentation(word, kernelSize=3, sigma=1, theta=1, minArea=15) # fix parameters\n",
    "\n",
    "    for (j, w) in enumerate(res):\n",
    "        (charBox, charImg) = w\n",
    "        (x, y, w, h) = charBox\n",
    "        if (w > 15):\n",
    "            if( h > 15):\n",
    "                if( pixel_density(charImg) < 0.55):\n",
    "                    characters.append(charImg)\n",
    "\n",
    "for char in characters:\n",
    "    showarray(char)\n",
    "    #print(pixel_density(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "##### word = words[2]\n",
    "h, w = word.shape\n",
    "num = 4\n",
    "chars = []\n",
    "for i in range(num):\n",
    "    part = math.floor(w / num)\n",
    "    char = word[:,part * i:(part * i) + part]\n",
    "    shape = cv2.resize(char,(32,48))\n",
    "    ret,thresh1 = cv2.threshold(shape,127,255,cv2.THRESH_BINARY)\n",
    "    chars.append(thresh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "chars = characters\n",
    "for char in chars:\n",
    "    showarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "fonts = []\n",
    "for item in class_names:\n",
    "    fonts.append(cv2.imread('habbakuk/' + item + '/standard.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for char in chars:\n",
    "#     char_pred = cv2.cvtColor(char, cv2.COLOR_BGR2GRAY)\n",
    "    char_pred = np.asarray(char[:], dtype='float32')\n",
    "    print(char_pred.shape)\n",
    "    char_pred = normalize(char_pred)\n",
    "    char_pred = char_pred.reshape(-1, 48, 32,1)\n",
    "\n",
    "    prediction = model.predict([char_pred])\n",
    "    for i in range(len(prediction)):\n",
    "        print('Predicted: ', prediction[i] * 100)\n",
    "    highest_index = np.argmax(prediction)\n",
    "    print('Index of class with highest probability: ',highest_index)\n",
    "    print('Value of highest probability: ', prediction[0][highest_index])\n",
    "    print('Name of predicted class: ', class_names[highest_index])\n",
    "    print('habbabuk/' + class_names[highest_index] + '/standard.png')\n",
    "    character_example = cv2.imread('habbakuk/' + str(class_names[highest_index]) + '/standard.png')\n",
    "    showarray(character_example)\n",
    "    showarray(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# for box in bounding_boxes:\n",
    "#     xStart = box[2]\n",
    "#     xEnd = box[0]\n",
    "#     y = box[1]\n",
    "#     winH = box[3] - y\n",
    "#     winWidth = 5\n",
    "#     while(xStart-winWidth >= xEnd) :\n",
    "#         hit = False\n",
    "#         winW = winWidth\n",
    "#         a = 0\n",
    "#         # While the image is not classified and the box has not reached the edge,\n",
    "#         # increase window size\n",
    "#         while(not hit and xStart-winW >= xEnd) :\n",
    "#             newX = xStart - winW\n",
    "#             # Draw the window\n",
    "#             clone = img.copy()\n",
    "#             cv2.rectangle(clone, (xStart, y), (newX, y + winH), (255, 0, 0), 2)\n",
    "#             cv2.rectangle(clone, (xStart,y),(xEnd,y + winH), (0,255,0), 2)\n",
    "#             cv2.imshow(\"Window\", clone)\n",
    "#             cv2.waitKey(0)\n",
    "#             # Check if the CNN returns a high probability for a letter\n",
    "#             # for prob in probabilities :\n",
    "#             #     if prob >= 0.75 :\n",
    "#             #         hit = True\n",
    "#             #         xStart = newX\n",
    "#             # # Increase size of window if nothing has been found\n",
    "#             winW += 5\n",
    "#             # this is done to ensure that the loop ends for now, because not\n",
    "#             # connected to cnn yet.\n",
    "#             hit = True\n",
    "#             xStart = newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# def get_resized_img(img, video_size):\n",
    "#     width, height = video_size  # these are the MAX dimensions\n",
    "#     video_ratio = width / height\n",
    "#     img_ratio = img.size[0] / img.size[1]\n",
    "#     if video_ratio >= 1:  # the video is wide\n",
    "#         if img_ratio <= video_ratio:  # image is not wide enough\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#         else:  # image is wider than video\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#     else:  # the video is tall\n",
    "#         if img_ratio >= video_ratio:  # image is not tall enough\n",
    "#             height_new = int(width / img_ratio)\n",
    "#             size_new = width, height_new\n",
    "#         else:  # image is taller than video\n",
    "#             width_new = int(height * img_ratio)\n",
    "#             size_new = width_new, height\n",
    "#     return np.asarray(img.resize(size_new, resample=Image.LANCZOS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# char = cv2.cvtColor(char, char, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "lines_to_next_cell": 2,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
